import streamlit as st
from st_files_connection import FilesConnection
#import cx_Oracle
import os
from dotenv import load_dotenv
import pandas as pd
import numpy as np
from datetime import timedelta
import seaborn as sns
import matplotlib.pyplot as plt
import boto3
import io
import time  # Importar time para simular a atualiza√ß√£o
import re
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.metrics import mean_squared_error, r2_score
import plotly.graph_objects as go

# Configurar a p√°gina
st.set_page_config(
    page_title="An√°lise Coorte e Reten√ß√£o, Modelagem e Machine Learning",  # T√≠tulo da p√°gina
    page_icon="üìä",  # √çcone da p√°gina (opcional)
    layout="wide"  # Ativar o Wide Mode
)


# Definir imagem de fundo
st.markdown(
    """
    <style>
    .reportview-container {
        background: url("https://villacamarao.com.br/wp-content/uploads/2021/05/Prancheta1_3.svg");
        background-size: cover;
        background-position: center;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# Fun√ß√£o para carregar dados
@st.cache_data(ttl=timedelta(hours=12))
def get_aws_credentials():
    """
    Obt√©m as credenciais da AWS de forma segura, priorizando vari√°veis de ambiente.
    Retorna um dicion√°rio com as credenciais.
    """
    # Prioridade 1: Vari√°veis de ambiente (Railway, Docker, etc.)
    if "AWS_ACCESS_KEY_ID" in os.environ:
        st.info("Carregando credenciais AWS a partir das vari√°veis de ambiente.")
        return {
            "aws_access_key_id": os.environ["AWS_ACCESS_KEY_ID"],
            "aws_secret_access_key": os.environ["AWS_SECRET_ACCESS_KEY"],
            "aws_default_region": os.environ["AWS_DEFAULT_REGION"]
        }
    
    # Prioridade 2: st.secrets (Streamlit Cloud)
    # Verifica se st.secrets existe e se a se√ß√£o 'aws' est√° presente
    elif hasattr(st, 'secrets') and "aws" in st.secrets:
        st.info("Carregando credenciais AWS a partir do Streamlit Secrets.")
        return {
            "aws_access_key_id": st.secrets["aws"]["aws_access_key_id"],
            "aws_secret_access_key": st.secrets["aws"]["aws_secret_access_key"],
            "aws_default_region": st.secrets["aws"]["aws_default_region"]
        }
    
    else:
        # Se nenhuma das op√ß√µes estiver dispon√≠vel, levanta um erro claro.
        raise ValueError("Credenciais da AWS n√£o encontradas. Configure as vari√°veis de ambiente ou o arquivo secrets.toml.")

# Agora, refatore sua fun√ß√£o carregar_dados para usar essa nova fun√ß√£o.
def carregar_dados():
    try:
        # 1. Obter as credenciais de forma segura
        aws_creds = get_aws_credentials()

        # 2. Criar o cliente S3 usando as credenciais desempacotadas
        s3_client = boto3.client(
            's3',
            aws_access_key_id=aws_creds["aws_access_key_id"],
            aws_secret_access_key=aws_creds["aws_secret_access_key"],
            region_name=aws_creds["aws_default_region"]
            # Alternativa mais limpa: boto3.client('s3', **aws_creds)
        )
        
        # 3. O resto da sua l√≥gica permanece igual
        bucket = 'datalake-out-etl'
        file_key = 'base-cohort-analysis/base-cohort-analysis.csv'
        
        obj = s3_client.get_object(Bucket=bucket, Key=file_key)
        df = pd.read_csv(io.BytesIO(obj['Body'].read()))
        
        if df is None or df.empty:
            raise Exception("Nenhum dado foi carregado do arquivo CSV")
            
        return df
        
    except Exception as e:
        st.error(f"Erro ao carregar dados: {e}")
        # A mensagem de erro agora ser√° muito mais espec√≠fica (ex: do ValueError ou do boto3)
        return None

# Fun√ß√£o para criar an√°lise de coorte (mant√©m igual)
def criar_cohort_analysis(df, modo='Normal'):
    """
    Fun√ß√£o para criar a an√°lise de coorte com dois modos diferentes
    """
    try:
        # Criar c√≥pia do DataFrame
        df_cohort = df.copy()
        
        # Converter datamovimento para datetime
        df_cohort['datamovimento'] = pd.to_datetime(df_cohort['datamovimento'])
        
        # Obter data m√≠nima e m√°xima do DataFrame
        data_inicial = df_cohort['datamovimento'].min().replace(day=1)
        data_final = df_cohort['datamovimento'].max().replace(day=1)
        
        if modo == 'Normal':
            df_cohort['COHORT_MES'] = df_cohort.groupby('codigocliente')['datamovimento'].transform('min').dt.strftime('%Y-%m')
        else:
            # Modo ajustado - identifica quebras na sequ√™ncia de compras
            df_cohort = df_cohort.sort_values(['codigocliente', 'datamovimento'])
            df_cohort['MES_ANO'] = df_cohort['datamovimento'].dt.strftime('%Y-%m')
            df_cohort['MES_ANTERIOR'] = df_cohort.groupby('codigocliente')['datamovimento'].shift()
            df_cohort['MESES_DIFF'] = (df_cohort['datamovimento'].dt.year * 12 + df_cohort['datamovimento'].dt.month) - \
                                    (df_cohort['MES_ANTERIOR'].dt.year * 12 + df_cohort['MES_ANTERIOR'].dt.month)
            df_cohort['NOVA_SAFRA'] = (df_cohort['MESES_DIFF'] > 1) | (df_cohort['MES_ANTERIOR'].isna())
            df_cohort['GRUPO_SAFRA'] = df_cohort.groupby('codigocliente')['NOVA_SAFRA'].cumsum()
            df_cohort['COHORT_MES'] = df_cohort.groupby(['codigocliente', 'GRUPO_SAFRA'])['datamovimento'].transform('min').dt.strftime('%Y-%m')
        
        # Criar m√™s da transa√ß√£o
        df_cohort['MES_TRANSACAO'] = df_cohort['datamovimento'].dt.strftime('%Y-%m')
        
        # Converter para datetime para c√°lculo correto do per√≠odo
        df_cohort['COHORT_MES'] = pd.to_datetime(df_cohort['COHORT_MES'])
        df_cohort['MES_TRANSACAO'] = pd.to_datetime(df_cohort['MES_TRANSACAO'])
        
        # Calcular o √≠ndice do per√≠odo
        df_cohort['PERIODO_INDEX'] = ((df_cohort['MES_TRANSACAO'].dt.year - df_cohort['COHORT_MES'].dt.year) * 12 +
                                    (df_cohort['MES_TRANSACAO'].dt.month - df_cohort['COHORT_MES'].dt.month))
        
        # Criar matriz de coorte
        cohort_data = df_cohort.groupby(['COHORT_MES', 'PERIODO_INDEX'])['codigocliente'].nunique().reset_index()
        
        # Criar todas as combina√ß√µes poss√≠veis de safras e per√≠odos
        cohort_meses = pd.date_range(start=data_inicial, end=data_final, freq='MS')
        max_periodo = ((data_final.year - data_inicial.year) * 12 + 
                      data_final.month - data_inicial.month)
        
        todas_combinacoes = pd.DataFrame([(cohort, periodo) 
                                        for cohort in cohort_meses 
                                        for periodo in range(int(max_periodo) + 1)],
                                       columns=['COHORT_MES', 'PERIODO_INDEX'])
        
        # Fazer merge com os dados reais
        cohort_data = todas_combinacoes.merge(cohort_data, 
                                            on=['COHORT_MES', 'PERIODO_INDEX'], 
                                            how='left')
        
        # Preencher valores nulos com 0
        cohort_data['codigocliente'] = cohort_data['codigocliente'].fillna(0)
        
        # Converter COHORT_MES para string no formato adequado
        cohort_data['COHORT_MES'] = cohort_data['COHORT_MES'].dt.strftime('%Y-%m')
        
        # Criar matriz pivotada
        cohort_matrix = cohort_data.pivot(index='COHORT_MES',
                                        columns='PERIODO_INDEX',
                                        values='codigocliente')
        
        # Calcular taxas de reten√ß√£o
        retention_matrix = cohort_matrix.divide(cohort_matrix[0], axis=0) * 100
        
        return retention_matrix
        
    except Exception as e:
        st.error(f"Erro ao criar an√°lise de coorte: {e}")
        return None

# Fun√ß√£o para plotar heatmap (mant√©m igual)
def plotar_heatmap_cohort(retention_matrix):
    """
    Fun√ß√£o para criar o heatmap da an√°lise de coorte em alta resolu√ß√£o
    """
    try:
        # Configurar o estilo do matplotlib
        plt.style.use('default')
        
        # Criar figura em alta resolu√ß√£o (FHD - 1920x1080)
        plt.figure(figsize=(16, 9), dpi=120)
        
        # Criar heatmap com cores invertidas
        ax = sns.heatmap(retention_matrix,
                        annot=True,
                        fmt='.1f',
                        cmap='RdYlGn',  # Invertido de RdYlGn_r para RdYlGn
                        vmin=0,
                        vmax=100,
                        annot_kws={'size': 8},
                        cbar_kws={'label': 'Taxa de Reten√ß√£o (%)'})
        
        # Melhorar a formata√ß√£o e estilo
        plt.title('An√°lise de Coorte - Taxa de Reten√ß√£o (%)', 
                 pad=20, 
                 size=14, 
                 fontweight='bold')
        
        plt.xlabel('N√∫mero de Meses', size=12, labelpad=10)
        plt.ylabel('M√™s de Aquisi√ß√£o', size=12, labelpad=10)
        
        # Rotacionar labels do eixo x para melhor legibilidade
        plt.xticks(rotation=0)
        plt.yticks(rotation=0)
        
        # Ajustar layout para evitar cortes
        plt.tight_layout()
        
        # Adicionar grade para melhor visualiza√ß√£o
        ax.grid(False)
        
        # Melhorar a apar√™ncia geral
        plt.rcParams['font.family'] = 'sans-serif'
        plt.rcParams['font.sans-serif'] = ['Arial']
        
        return plt
        
    except Exception as e:
        st.error(f"Erro ao criar heatmap: {e}")
        st.write("Estilos dispon√≠veis:", plt.style.available)  # Debug
        return None

# Fun√ß√£o para criar tabela de cobertura (mant√©m igual)
def criar_tabela_cobertura(df):
    """
    Fun√ß√£o para criar a tabela de cobertura de vendas
    """
    try:
        # Criar c√≥pia do DataFrame
        df_cobertura = df.copy()
        
        # Converter DATAMOVIMENTO para datetime
        df_cobertura['datamovimento'] = pd.to_datetime(df_cobertura['datamovimento'])
        
        # Criar colunas de ano-m√™s para safra e movimento
        df_cobertura['SAFRA'] = df_cobertura.groupby('codigocliente')['datamovimento'].transform('min').dt.strftime('%Y-%m')
        df_cobertura['MOVIMENTO'] = df_cobertura['datamovimento'].dt.strftime('%Y-%m')
        
        # Agrupar e contar clientes √∫nicos
        tabela_cobertura = df_cobertura.groupby(['SAFRA', 'MOVIMENTO'])['codigocliente'].nunique().reset_index()
        
        # Obter data m√≠nima e m√°xima do DataFrame
        data_inicial = df_cobertura['datamovimento'].min().replace(day=1)
        data_final = df_cobertura['datamovimento'].max().replace(day=1)
        
        # Criar range de datas para safras e movimentos
        todas_datas = pd.date_range(start=data_inicial, end=data_final, freq='MS')
        todas_datas_str = todas_datas.strftime('%Y-%m')
        
        # Criar todas as combina√ß√µes poss√≠veis
        todas_combinacoes = pd.DataFrame([(safra, movimento) 
                                        for safra in todas_datas_str 
                                        for movimento in todas_datas_str],
                                       columns=['SAFRA', 'MOVIMENTO'])
        
        # Fazer merge com os dados reais
        tabela_final = todas_combinacoes.merge(tabela_cobertura, 
                                             on=['SAFRA', 'MOVIMENTO'], 
                                             how='left')
        
        # Criar tabela pivotada
        tabela_final = tabela_final.pivot(index='SAFRA', 
                                        columns='MOVIMENTO', 
                                        values='codigocliente')
        
        # Adicionar total por linha
        tabela_final['Total Geral'] = tabela_final.sum(axis=1)
        
        # Adicionar total por coluna
        total_colunas = tabela_final.sum().to_frame().T
        total_colunas.index = ['Total Geral']
        
        # Criar linha com valores iniciais de cada safra
        valores_iniciais = pd.DataFrame(index=['Novos Clientes'])
        for coluna in tabela_final.columns:
            if coluna == 'Total Geral':
                valores_iniciais[coluna] = 0
            else:
                # Pegar apenas os valores onde o m√™s da coluna coincide com o m√™s da safra
                valores_iniciais[coluna] = tabela_final[coluna][tabela_final.index == coluna].fillna(0).sum()
        
        # Concatenar com a tabela original e totais
        tabela_final = pd.concat([tabela_final, total_colunas, valores_iniciais])
        
        # Formatar tabela
        tabela_final = tabela_final.fillna(0).astype(int)
        
        return tabela_final
        
    except Exception as e:
        st.error(f"Erro ao criar tabela de cobertura: {e}")
        return None

def criar_tabela_faturamento(df):
    """
    Fun√ß√£o para criar a tabela de faturamento de vendas
    """
    try:
        # Criar c√≥pia do DataFrame
        df_faturamento = df.copy()
        
        # Converter datamovimento para datetime
        df_faturamento['datamovimento'] = pd.to_datetime(df_faturamento['datamovimento'])
        
        # Obter data m√≠nima e m√°xima do DataFrame
        data_inicial = df_faturamento['datamovimento'].min().replace(day=1)
        data_final = df_faturamento['datamovimento'].max().replace(day=1)
        
        # Criar range de datas baseado nos dados
        todas_datas = pd.date_range(start=data_inicial, end=data_final, freq='MS')
        todas_datas = pd.DataFrame({'MOVIMENTO': todas_datas.strftime('%Y-%m')})
        
        # Criar colunas de ano-m√™s para safra e movimento
        df_faturamento['SAFRA'] = df_faturamento.groupby('codigocliente')['datamovimento'].transform('min').dt.strftime('%Y-%m')
        df_faturamento['MOVIMENTO'] = df_faturamento['datamovimento'].dt.strftime('%Y-%m')
        
        # Agrupar e somar faturamento
        tabela_faturamento = df_faturamento.groupby(['SAFRA', 'MOVIMENTO'])['faturamento'].sum().reset_index()
        
        # Criar todas as combina√ß√µes poss√≠veis
        todas_datas = pd.date_range(start=data_inicial, end=data_final, freq='MS')
        todas_datas_str = todas_datas.strftime('%Y-%m')
        
        todas_combinacoes = pd.DataFrame([(safra, movimento) 
                                        for safra in todas_datas_str 
                                        for movimento in todas_datas_str],
                                       columns=['SAFRA', 'MOVIMENTO'])
        
        # Fazer merge com os dados reais
        tabela_final = todas_combinacoes.merge(tabela_faturamento, 
                                             on=['SAFRA', 'MOVIMENTO'], 
                                             how='left')
        
        # Preencher valores nulos com 0
        tabela_final['faturamento'] = tabela_final['faturamento'].fillna(0)
        
        # Criar tabela pivotada
        tabela_pivot = tabela_final.pivot(index='SAFRA', 
                                        columns='MOVIMENTO', 
                                        values='faturamento')
        
        # Ordenar as colunas cronologicamente
        tabela_pivot = tabela_pivot.reindex(sorted(tabela_pivot.columns), axis=1)
        
        # Adicionar total por linha
        tabela_pivot['Total Geral'] = tabela_pivot.sum(axis=1)
        
        # Adicionar total por coluna
        total_colunas = tabela_pivot.sum().to_frame().T
        total_colunas.index = ['Total Geral']
        
        # Criar linha com valores iniciais de cada safra
        valores_iniciais = pd.DataFrame(index=['Faturamento Inicial'])
        for coluna in tabela_pivot.columns:
            if coluna == 'Total Geral':
                valores_iniciais[coluna] = 0
            else:
                valores_iniciais[coluna] = tabela_pivot[coluna][tabela_pivot.index == coluna].fillna(0).sum()
        
        # Concatenar com a tabela original e totais
        tabela_final = pd.concat([tabela_pivot, total_colunas, valores_iniciais])
        
        # Formatar tabela
        tabela_final = tabela_final.fillna(0).round(2)
        
        return tabela_final
        
    except Exception as e:
        st.error(f"Erro ao criar tabela de faturamento: {e}")
        return None

def criar_tabela_margem(df):
    """
    Fun√ß√£o para criar a tabela de margem de vendas
    """
    try:
        # Criar c√≥pia do DataFrame
        df_margem = df.copy()
        
        # Converter datamovimento para datetime
        df_margem['datamovimento'] = pd.to_datetime(df_margem['datamovimento'])
        
        # Obter data m√≠nima e m√°xima do DataFrame
        data_inicial = df_margem['datamovimento'].min().replace(day=1)
        data_final = df_margem['datamovimento'].max().replace(day=1)
        
        # Criar range de datas baseado nos dados
        todas_datas = pd.date_range(start=data_inicial, end=data_final, freq='MS')
        todas_datas = pd.DataFrame({'MOVIMENTO': todas_datas.strftime('%Y-%m')})
        
        # Calcular o custo total e a margem
        df_margem['custototal'] = df_margem['custo'] #* df_margem['quantidade']
        df_margem['margem'] = df_margem['faturamento'] - df_margem['custototal']
        
        # Criar colunas de ano-m√™s para safra e movimento
        df_margem['SAFRA'] = df_margem.groupby('codigocliente')['datamovimento'].transform('min').dt.strftime('%Y-%m')
        df_margem['MOVIMENTO'] = df_margem['datamovimento'].dt.strftime('%Y-%m')
        
        # Agrupar e somar margem
        tabela_margem = df_margem.groupby(['SAFRA', 'MOVIMENTO'])['margem'].sum().reset_index()
        
        # Criar todas as combina√ß√µes poss√≠veis
        todas_datas = pd.date_range(start=data_inicial, end=data_final, freq='MS')
        todas_datas_str = todas_datas.strftime('%Y-%m')
        
        todas_combinacoes = pd.DataFrame([(safra, movimento) 
                                        for safra in todas_datas_str 
                                        for movimento in todas_datas_str],
                                       columns=['SAFRA', 'MOVIMENTO'])
        
        # Fazer merge com os dados reais
        tabela_final = todas_combinacoes.merge(tabela_margem, 
                                             on=['SAFRA', 'MOVIMENTO'], 
                                             how='left')
        
        # Preencher valores nulos com 0
        tabela_final['margem'] = tabela_final['margem'].fillna(0)
        
        # Criar tabela pivotada
        tabela_pivot = tabela_final.pivot(index='SAFRA', 
                                        columns='MOVIMENTO', 
                                        values='margem')
        
        # Ordenar as colunas cronologicamente
        tabela_pivot = tabela_pivot.reindex(sorted(tabela_pivot.columns), axis=1)
        
        # Adicionar total por linha
        tabela_pivot['Total Geral'] = tabela_pivot.sum(axis=1)
        
        # Adicionar total por coluna
        total_colunas = tabela_pivot.sum().to_frame().T
        total_colunas.index = ['Total Geral']
        
        # Criar linha com valores iniciais de cada safra
        valores_iniciais = pd.DataFrame(index=['Margem Inicial'])
        for coluna in tabela_pivot.columns:
            if coluna == 'Total Geral':
                valores_iniciais[coluna] = 0
            else:
                valores_iniciais[coluna] = tabela_pivot[coluna][tabela_pivot.index == coluna].fillna(0).sum()
        
        # Concatenar com a tabela original e totais
        tabela_final = pd.concat([tabela_pivot, total_colunas, valores_iniciais])
        
        # Formatar tabela
        tabela_final = tabela_final.fillna(0).round(2)
        
        return tabela_final
        
    except Exception as e:
        st.error(f"Erro ao criar tabela de margem: {e}")
        return None

# Fun√ß√£o para criar tabela de notas emitidas
def criar_tabela_notas(df):
    """
    Fun√ß√£o para criar a tabela de notas emitidas
    """
    try:
        # Criar c√≥pia do DataFrame
        df_notas = df.copy()
        
        # Converter DATAMOVIMENTO para datetime
        df_notas['datamovimento'] = pd.to_datetime(df_notas['datamovimento'])
        
        # Criar colunas de ano-m√™s para safra e movimento
        df_notas['SAFRA'] = df_notas.groupby('codigocliente')['datamovimento'].transform('min').dt.strftime('%Y-%m')
        df_notas['MOVIMENTO'] = df_notas['datamovimento'].dt.strftime('%Y-%m')
        
        # Agrupar e contar notas emitidas de forma distinta
        tabela_notas = df_notas.groupby(['SAFRA', 'MOVIMENTO'])['notasaida'].nunique().reset_index()
        
        # Obter data m√≠nima e m√°xima do DataFrame
        data_inicial = df_notas['datamovimento'].min().replace(day=1)
        data_final = df_notas['datamovimento'].max().replace(day=1)
        
        # Criar range de datas para safras e movimentos
        todas_datas = pd.date_range(start=data_inicial, end=data_final, freq='MS')
        todas_datas_str = todas_datas.strftime('%Y-%m')
        
        # Criar todas as combina√ß√µes poss√≠veis
        todas_combinacoes = pd.DataFrame([(safra, movimento) 
                                        for safra in todas_datas_str 
                                        for movimento in todas_datas_str],
                                       columns=['SAFRA', 'MOVIMENTO'])
        
        # Fazer merge com os dados reais
        tabela_final = todas_combinacoes.merge(tabela_notas, 
                                             on=['SAFRA', 'MOVIMENTO'], 
                                             how='left')
        
        # Preencher valores nulos com 0
        tabela_final['notasaida'] = tabela_final['notasaida'].fillna(0)
        
        # Criar tabela pivotada
        tabela_pivot = tabela_final.pivot(index='SAFRA', 
                                        columns='MOVIMENTO', 
                                        values='notasaida')
        
        # Ordenar as colunas cronologicamente
        tabela_pivot = tabela_pivot.reindex(sorted(tabela_pivot.columns), axis=1)
        
        # Adicionar total por linha
        tabela_pivot['Total Geral'] = tabela_pivot.sum(axis=1)
        
        # Adicionar total por coluna
        total_colunas = tabela_pivot.sum().to_frame().T
        total_colunas.index = ['Total Geral']
        
        # Criar linha com valores iniciais de cada safra
        valores_iniciais = pd.DataFrame(index=['Notas Iniciais'])
        for coluna in tabela_pivot.columns:
            if coluna == 'Total Geral':
                valores_iniciais[coluna] = 0
            else:
                valores_iniciais[coluna] = tabela_pivot[coluna][tabela_pivot.index == coluna].fillna(0).sum()
        
        # Concatenar com a tabela original e totais
        tabela_final = pd.concat([tabela_pivot, total_colunas, valores_iniciais])
        
        # Formatar tabela
        tabela_final = tabela_final.fillna(0).astype(int)
        
        return tabela_final
        
    except Exception as e:
        st.error(f"Erro ao criar tabela de notas: {e}")
        return None

# Fun√ß√£o para criar tabela de quantidade de vendas
def criar_tabela_quantidade(df):
    """
    Fun√ß√£o para criar a tabela de quantidade de vendas
    """
    try:
        # Criar c√≥pia do DataFrame
        df_quantidade = df.copy()
        
        # Converter DATAMOVIMENTO para datetime
        df_quantidade['datamovimento'] = pd.to_datetime(df_quantidade['datamovimento'])
        
        # Criar colunas de ano-m√™s para safra e movimento
        df_quantidade['SAFRA'] = df_quantidade.groupby('codigocliente')['datamovimento'].transform('min').dt.strftime('%Y-%m')
        df_quantidade['MOVIMENTO'] = df_quantidade['datamovimento'].dt.strftime('%Y-%m')
        
        # Agrupar e somar quantidade
        tabela_quantidade = df_quantidade.groupby(['SAFRA', 'MOVIMENTO'])['quantidade'].sum().reset_index()
        
        # Obter data m√≠nima e m√°xima do DataFrame
        data_inicial = df_quantidade['datamovimento'].min().replace(day=1)
        data_final = df_quantidade['datamovimento'].max().replace(day=1)
        
        # Criar range de datas para safras e movimentos
        todas_datas = pd.date_range(start=data_inicial, end=data_final, freq='MS')
        todas_datas_str = todas_datas.strftime('%Y-%m')
        
        # Criar todas as combina√ß√µes poss√≠veis
        todas_combinacoes = pd.DataFrame([(safra, movimento) 
                                        for safra in todas_datas_str 
                                        for movimento in todas_datas_str],
                                       columns=['SAFRA', 'MOVIMENTO'])
        
        # Fazer merge com os dados reais
        tabela_final = todas_combinacoes.merge(tabela_quantidade, 
                                             on=['SAFRA', 'MOVIMENTO'], 
                                             how='left')
        
        # Preencher valores nulos com 0
        tabela_final['quantidade'] = tabela_final['quantidade'].fillna(0)
        
        # Criar tabela pivotada
        tabela_pivot = tabela_final.pivot(index='SAFRA', 
                                        columns='MOVIMENTO', 
                                        values='quantidade')
        
        # Ordenar as colunas cronologicamente
        tabela_pivot = tabela_pivot.reindex(sorted(tabela_pivot.columns), axis=1)
        
        # Adicionar total por linha
        tabela_pivot['Total Geral'] = tabela_pivot.sum(axis=1)
        
        # Adicionar total por coluna
        total_colunas = tabela_pivot.sum().to_frame().T
        total_colunas.index = ['Total Geral']
        
        # Criar linha com valores iniciais de cada safra
        valores_iniciais = pd.DataFrame(index=['Quantidade Inicial'])
        for coluna in tabela_pivot.columns:
            if coluna == 'Total Geral':
                valores_iniciais[coluna] = 0
            else:
                valores_iniciais[coluna] = tabela_pivot[coluna][tabela_pivot.index == coluna].fillna(0).sum()
        
        # Concatenar com a tabela original e totais
        tabela_final = pd.concat([tabela_pivot, total_colunas, valores_iniciais])
        
        # Formatar tabela
        tabela_final = tabela_final.fillna(0).astype(int)
        
        return tabela_final
        
    except Exception as e:
        st.error(f"Erro ao criar tabela de quantidade: {e}")
        return None

# Fun√ß√£o para criar tabela de margem percentual
def criar_tabela_margem_percentual(df):
    """
    Fun√ß√£o para criar a tabela de margem percentual
    """
    try:
        # Criar c√≥pia do DataFrame
        df_margem = df.copy()
        
        # Converter DATAMOVIMENTO para datetime
        df_margem['datamovimento'] = pd.to_datetime(df_margem['datamovimento'])
        
        # Criar colunas de ano-m√™s para safra e movimento
        df_margem['SAFRA'] = df_margem.groupby('codigocliente')['datamovimento'].transform('min').dt.strftime('%Y-%m')
        df_margem['MOVIMENTO'] = df_margem['datamovimento'].dt.strftime('%Y-%m')
        
        # Calcular a margem
        df_margem['margem'] = df_margem['faturamento'] - df_margem['custo']
        
        # Calcular a margem percentual
        df_margem['margem_percentual'] = (df_margem['margem'] / df_margem['faturamento']) * 100
        
        # Agrupar e calcular a soma da margem e do faturamento
        tabela_margem_percentual = df_margem.groupby(['SAFRA', 'MOVIMENTO']).agg(
            margem_total=('margem', 'sum'),
            faturamento_total=('faturamento', 'sum')
        ).reset_index()
        
        # Calcular a margem percentual
        tabela_margem_percentual['margem_percentual'] = (tabela_margem_percentual['margem_total'] / tabela_margem_percentual['faturamento_total']) * 100
        
        # Formatar os n√∫meros para usar v√≠rgula como separador decimal
        # tabela_margem_percentual['margem_percentual'] = tabela_margem_percentual['margem_percentual'].apply(lambda x: f"{x:,.2f}".replace('.', ','))

        # Obter data m√≠nima e m√°xima do DataFrame
        data_inicial = df_margem['datamovimento'].min().replace(day=1)
        data_final = df_margem['datamovimento'].max().replace(day=1)
        
        # Criar range de datas para safras e movimentos
        todas_datas = pd.date_range(start=data_inicial, end=data_final, freq='MS')
        todas_datas_str = todas_datas.strftime('%Y-%m')
        
        # Criar todas as combina√ß√µes poss√≠veis
        todas_combinacoes = pd.DataFrame([(safra, movimento) 
                                        for safra in todas_datas_str 
                                        for movimento in todas_datas_str],
                                       columns=['SAFRA', 'MOVIMENTO'])
        
        # Fazer merge com os dados reais
        tabela_final = todas_combinacoes.merge(tabela_margem_percentual, 
                                             on=['SAFRA', 'MOVIMENTO'], 
                                             how='left')
        
        # Preencher valores nulos com 0
        tabela_final['margem_percentual'] = tabela_final['margem_percentual'].fillna(0)
        
        # Criar tabela pivotada
        tabela_pivot = tabela_final.pivot(index='SAFRA', 
                                        columns='MOVIMENTO', 
                                        values='margem_percentual')
        
        # Ordenar as colunas cronologicamente
        tabela_pivot = tabela_pivot.reindex(sorted(tabela_pivot.columns), axis=1)
        
        # Adicionar total por linha
        tabela_pivot['Total Geral'] = (tabela_pivot.sum(axis=1) / tabela_final.groupby('SAFRA')['faturamento_total'].sum()).fillna(0) * 100
        
        # Adicionar total por coluna
        total_colunas = (tabela_pivot.sum() / tabela_final.groupby('MOVIMENTO')['faturamento_total'].sum()).to_frame().T
        total_colunas.index = ['Total Geral']
        
        # Criar linha com valores iniciais de cada safra
        valores_iniciais = pd.DataFrame(index=['Margem Inicial'])
        for coluna in tabela_pivot.columns:
            if coluna == 'Total Geral':
                valores_iniciais[coluna] = 0
            else:
                valores_iniciais[coluna] = tabela_pivot[coluna][tabela_pivot.index == coluna].fillna(0).mean()
        
        # Concatenar com a tabela original e totais
        tabela_final = pd.concat([tabela_pivot, total_colunas, valores_iniciais])
        
        # Formatar tabela
        tabela_final = tabela_final.fillna(0).round(2)
        
        return tabela_final
        
    except Exception as e:
        st.error(f"Erro ao criar tabela de margem percentual: {e}")
        return None

# Fun√ß√£o para carregar dados com barra de progresso
def carregar_dados_com_progresso():
    with st.spinner("Atualizando a base de dados..."):
        # Simular um tempo de carregamento (substitua isso pela sua l√≥gica de carregamento)
        time.sleep(2)  # Simula um atraso de 2 segundos
        
        # Aqui voc√™ deve chamar a fun√ß√£o real para carregar os dados
        df = carregar_dados()  # Chame sua fun√ß√£o de carregamento de dados
        st.session_state.df = df  # Armazena o DataFrame no session_state
        return df

# Carregar dados uma √∫nica vez
df = carregar_dados_com_progresso()

# Renomear colunas para min√∫sculas
# df.columns = df.columns.str.lower()

# Verificar as colunas do DataFrame
#st.write("Colunas dispon√≠veis no DataFrame:", df.columns.tolist())

# Remover filiais 1 e 5 do DataFrame
if df is not None:
    df = df[~df['codigofilial'].astype(str).isin(['1', '5', '2'])]
    
    # Resetar o √≠ndice ap√≥s a remo√ß√£o
    df = df.reset_index(drop=True)

# T√≠tulo da aplica√ß√£o
st.title("An√°lise Coorte e Reten√ß√£o")
st.subheader("Villa Camar√£o!")

# Verifica se as credenciais da Microsoft est√£o nas vari√°veis de ambiente
if "MS_CLIENT_ID" not in os.environ or "MS_CLIENT_SECRET" not in os.environ:
    st.error("As credenciais de autentica√ß√£o da Microsoft n√£o foram configuradas. Contate o administrador.")
else:
    # Configura o provedor de autentica√ß√£o
    auth_providers = {
        "microsoft": {
            "client_id": os.environ.get("MS_CLIENT_ID"),
            "client_secret": os.environ.get("MS_CLIENT_SECRET"),
            "redirect_uri": "https://cohort-analysis-production.up.railway.app/_st_login", # IMPORTANTE: Usar a URL de produ√ß√£o aqui
            "tenant_id": "common", # Ou o ID do seu tenant espec√≠fico para maior seguran√ßa
            "label": "Login com Microsoft (Villa Camar√£o)"
        }
    }

    # Exibe o bot√£o de login
    login_button = st.login(providers="microsoft")

    if login_button.is_logged_in:
        # Pega o email do usu√°rio logado
        user_email = login_button.user.email
        #allowed_domain = "villacamarao.com.br"
        
        st.sidebar.write(f"Logado como: {user_email}")

        # Verifica se o dom√≠nio do email √© o permitido
        if user_email.endswith(allowed_domain):
            # --- SE O ACESSO FOR PERMITIDO, MOSTRA O APP ---
            st.header("Dashboard Principal")
            
            # Carrega e exibe os dados
            df_cohort = carregar_dados()

            if df_cohort is not None:
                st.success("Dados carregados com sucesso!")
                st.dataframe(df_cohort)
                # ... coloque aqui o resto do seu aplicativo, gr√°ficos, etc.
            else:
                st.warning("N√£o foi poss√≠vel carregar os dados do dashboard.")

        else:
            # --- SE O DOM√çNIO N√ÉO FOR PERMITIDO ---
            st.error(f"Acesso Negado. Apenas usu√°rios com o dom√≠nio '{allowed_domain}' s√£o permitidos.")
            st.warning(f"Seu email ({user_email}) n√£o tem permiss√£o para acessar esta aplica√ß√£o.")
            st.info("Por favor, fa√ßa logout e tente novamente com uma conta autorizada.")
            # O bot√£o de logout j√° √© exibido automaticamente por st.login

    else:
        st.info("Por favor, fa√ßa login para acessar o dashboard.")
        st.image("https://www.villacamarao.com.br/wp-content/uploads/2023/12/logo-villa-camarao.png", width=300)

# Fim do treche de autentica√ß√£o

# Adicionar logo
st.image("https://villacamarao.com.br/wp-content/uploads/2021/05/Prancheta1_3.svg", width=150)

st.divider()

# Sidebar com filtros
st.sidebar.header("Filtros")

# Inicializar filtros apenas se df n√£o for None
if df is not None:
    # Converter DATAMOVIMENTO para datetime se ainda n√£o estiver
    df['datamovimento'] = pd.to_datetime(df['datamovimento'])
    
    # Obter data m√≠nima e m√°xima do DataFrame
    data_min = df['datamovimento'].min()
    data_max = df['datamovimento'].max()
    
    # Filtro de Data
    st.sidebar.subheader("Filtro de Per√≠odo")
    data_selecionada = st.sidebar.date_input(
        "Selecione o m√™s/ano inicial:",
        value=data_min,
        min_value=data_min,
        max_value=data_max
    )
    
    # Converter data selecionada para datetime
    data_filtro = pd.to_datetime(data_selecionada)
    
    # Filtro de Filial
    filiais_disponiveis = ['Todas'] + sorted([str(x) for x in df['codigofilial'].unique() if pd.notna(x)])
    filial_selecionada = st.sidebar.selectbox(
        'Selecione a Filial:',
        filiais_disponiveis
    )
    
        # Filtro de Gerente de Carteira
    gerentes_carteira_disponiveis = ['Todos'] + sorted([str(x) for x in df['gerentecarteira'].unique() if pd.notna(x)])
    gerente_carteira_selecionado = st.sidebar.selectbox(
        'Selecione o Gerente de Carteira:',
        gerentes_carteira_disponiveis
    )
    
    # Filtro de Gerente de Venda
    gerentes_venda_disponiveis = ['Todos'] + sorted([str(x) for x in df['gerentevenda'].unique() if pd.notna(x)])
    gerente_venda_selecionado = st.sidebar.selectbox(
        'Selecione o Gerente de Venda:',
        gerentes_venda_disponiveis
    )

    # Filtro de Cluster
    clusters_disponiveis = ['Todos'] + sorted([str(x) for x in df['nome_cluster'].unique() if pd.notna(x)])
    cluster_selecionado = st.sidebar.selectbox(
        'Selecione o Cluster:',
        clusters_disponiveis
    )
    
    # Filtro de Rede
    redes_disponiveis = ['Todas'] + sorted([str(x) for x in df['rede'].unique() if pd.notna(x)])
    rede_selecionada = st.sidebar.selectbox(
        'Selecione a Rede:',
        redes_disponiveis
    )
    
    # Filtro de Cliente
    clientes_disponiveis = ['Todos'] + sorted([str(x) for x in df['cliente'].unique() if pd.notna(x)])
    cliente_selecionado = st.sidebar.selectbox(
        'Selecione o Cliente:',
        clientes_disponiveis
    )
    
    # Filtro de UF do Cliente
    ufs_disponiveis = ['Todos'] + sorted([str(x) for x in df['ufcliente'].unique() if pd.notna(x)])
    uf_selecionada = st.sidebar.selectbox(
        'Selecione a UF do Cliente:',
        ufs_disponiveis,
        index=0  # Op√ß√£o padr√£o (primeira UF selecionada)
    )
    
    # Aplicar filtros
    df_filtrado = df.copy()
    
    # Aplicar filtro de data (maior ou igual √† data selecionada)
    df_filtrado = df_filtrado[df_filtrado['datamovimento'] >= data_filtro]
    
    if filial_selecionada != 'Todas':
        df_filtrado = df_filtrado[df_filtrado['codigofilial'].astype(str) == filial_selecionada]
    
    if cluster_selecionado != 'Todos':
        df_filtrado = df_filtrado[df_filtrado['nome_cluster'].astype(str) == cluster_selecionado]
    
    if rede_selecionada != 'Todas':
        df_filtrado = df_filtrado[df_filtrado['rede'].astype(str) == rede_selecionada]
    
    if cliente_selecionado != 'Todos':
        df_filtrado = df_filtrado[df_filtrado['cliente'].astype(str) == cliente_selecionado]
    
    # Aplicar filtro de Gerente de Carteira
    if gerente_carteira_selecionado != 'Todos':
        df_filtrado = df_filtrado[df_filtrado['gerentecarteira'].astype(str) == gerente_carteira_selecionado]
    
    # Aplicar filtro de Gerente de Venda
    if gerente_venda_selecionado != 'Todos':
        df_filtrado = df_filtrado[df_filtrado['gerentevenda'].astype(str) == gerente_venda_selecionado]
    
    # Aplicar filtro de UF do Cliente
    if uf_selecionada  != 'Todos':
        df_filtrado = df_filtrado[df_filtrado['ufcliente'].astype(str) == uf_selecionada]
    
    # Adicionar selectbox para escolher entre amostra e dados completos
    opcao_dados = st.sidebar.selectbox(
        "Escolha o tipo de dados:",
        ["Amostra", "Dados Completos"],
        index=1  # Amostra como padr√£o
    )

    # Se a op√ß√£o for "Amostra", usar uma amostra dos dados
    if opcao_dados == "Amostra":
        if len(df_filtrado) > 10000:  # Exemplo de limite
            df_filtrado = df_filtrado.sample(n=10000, random_state=1)

    # Mostrar contagem de registros ap√≥s filtros
    st.sidebar.markdown("---")
    st.sidebar.write("### Resumo dos Dados")
    st.sidebar.write(f"Total de registros: {len(df_filtrado):,}")
    
    # Verificar se existem dados ap√≥s os filtros
    if len(df_filtrado) > 0:
        st.sidebar.write(f"Per√≠odo dos dados filtrados:")
        st.sidebar.write(f"De: {df_filtrado['datamovimento'].min().strftime('%d/%m/%Y')}")
        st.sidebar.write(f"At√©: {df_filtrado['datamovimento'].max().strftime('%d/%m/%Y')}")
        
        # Mostrar quantidade de meses no per√≠odo
        meses_periodo = (df_filtrado['datamovimento'].max().year - df_filtrado['datamovimento'].min().year) * 12 + \
                       df_filtrado['datamovimento'].max().month - df_filtrado['datamovimento'].min().month + 1
        st.sidebar.write(f"Total de meses: {meses_periodo}")
    else:
        st.sidebar.warning("Nenhum dado encontrado para os filtros selecionados.")

# Adicionar seletor de modo de coorte na sidebar
st.sidebar.markdown("---")
modo_coorte = st.sidebar.radio(
    "Modo de An√°lise de Coorte:",
    ["Normal", "Ajustado"],
    help="Normal: Considera a primeira compra como safra\nAjustado: Reinicia a safra quando h√° interrup√ß√£o nas compras"
)

# Navega√ß√£o entre p√°ginas
pagina = st.sidebar.selectbox("Escolha uma p√°gina:", ["P√°gina Inicial", "Gr√°fico de reten√ß√£o", "An√°lise Coorte", "An√°lise Explorat√≥ria", "Modelagem e Treinamento"])

if pagina == "P√°gina Inicial":
    st.subheader("Visualiza√ß√£o dos Dados")
    
    if df is not None:
        # Mostrar as primeiras linhas do DataFrame
        # st.write("### Primeiras linhas do DataFrame:")
        # st.dataframe(df.head(10))
        st.markdown("""
        **Proposta do projeto:**
        - Entender o comportamento de compra (safra) dos clientes
        - Os dados s√£o atualizados diariamente
        - Os dados s√£o divididos em quantidade de clientes, faturamento, margem e n√∫mero de notas/pedidos
        - A coluna 'Total Geral' mostra o total por safra
        - A linha 'Total Geral' mostra o total por m√™s da venda
        - A linha 'Total Inicial' mostra o total da primeira venda do m√™s
        - Utilize a barra lateral para filtrar os registros e navegar entre as p√°ginas
        """)
        
        # Mostrar informa√ß√µes b√°sicas sobre o DataFrame
        st.write("### Informa√ß√µes do DataFrame:")
        st.write(f"Total de registros: {len(df):,}")
        st.write(f"Total de colunas: {len(df.columns)}")
        st.write("Todos os direitos reservados.")
    
elif pagina == "Gr√°fico de reten√ß√£o":
    st.write("Bem-vindo √† P√°gina de Gr√°fico de reten√ß√£o!")
    
    if df is not None:
        st.success("Dados carregados com sucesso!")
        
        # Criar an√°lise de coorte com o modo selecionado
        retention_matrix = criar_cohort_analysis(df_filtrado, modo=modo_coorte)
        
        if retention_matrix is not None:
            st.write(f"## An√°lise de Coorte - Modo {modo_coorte}")
            
            # Adicionar informa√ß√µes dos filtros aplicados
            if filial_selecionada != 'Todas' or cluster_selecionado != 'Todos':
                st.write("### Filtros Aplicados:")
                if filial_selecionada != 'Todas':
                    st.write(f"- Filial: {filial_selecionada}")
                if cluster_selecionado != 'Todos':
                    st.write(f"- Cluster: {cluster_selecionado}")
            
            # Criar e exibir o heatmap
            fig = plotar_heatmap_cohort(retention_matrix)
            if fig is not None:
                st.pyplot(fig, use_container_width=True)
            
elif pagina == "An√°lise Coorte":
    #st.write("## An√°lise Coorte")
    
    if df is not None:
        # Adicionar informa√ß√µes dos filtros aplicados
        if filial_selecionada != 'Todas' or cluster_selecionado != 'Todos':
            st.write("#### Filtros Aplicados:")
            if filial_selecionada != 'Todas':
                st.write(f"- Filial: {filial_selecionada}")
            if cluster_selecionado != 'Todos':
                st.write(f"- Cluster: {cluster_selecionado}")
        
        # Criar tabs para as diferentes visualiza√ß√µes
        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["Cobertura de Clientes", "Faturamento", "Margem", "Margem Percentual", "Notas Emitidas", "Volume"])
        
        with tab1:
            st.write("### Tabela de Cobertura de Clientes")
            tabela_cobertura = criar_tabela_cobertura(df_filtrado)
            
            if tabela_cobertura is not None:
                st.dataframe(
                    tabela_cobertura,
                    use_container_width=True,
                    height=400
                )
                
                st.markdown("""
                **Como interpretar a tabela:**
                - As linhas mostram o m√™s de primeira compra (safra) dos clientes
                - As colunas mostram os meses subsequentes de compra
                - Os n√∫meros representam a quantidade de clientes √∫nicos
                - A coluna 'Total Geral' mostra o total de clientes por safra
                """)
        
        with tab2:
            st.write("### Tabela de Faturamento")
            tabela_faturamento = criar_tabela_faturamento(df_filtrado)
            
            if tabela_faturamento is not None:
                st.dataframe(
                    tabela_faturamento.style.format("R$ {:,.2f}"),
                    use_container_width=True,
                    height=400
                )
                
                st.markdown("""
                **Como interpretar a tabela:**
                - As linhas mostram o m√™s de primeira compra (safra) dos clientes
                - As colunas mostram os meses subsequentes de compra
                - Os valores representam o faturamento total
                - A coluna 'Total Geral' mostra o faturamento total por safra
                """)
        
        with tab3:
            st.write("### Tabela de Margem")
            tabela_margem = criar_tabela_margem(df_filtrado)
            
            if tabela_margem is not None:
                st.dataframe(
                    tabela_margem.style.format("R$ {:,.2f}"),
                    use_container_width=True,
                    height=400
                )
                
                st.markdown("""
                **Como interpretar a tabela:**
                - As linhas mostram o m√™s de primeira compra (safra) dos clientes
                - As colunas mostram os meses subsequentes de compra
                - Os valores representam a margem (Faturamento - Custo)
                - A coluna 'Total Geral' mostra a margem total por safra
                """)

        with tab4:  # Nova aba para a tabela de margem percentual
            st.write("### Tabela de Margem Percentual")
            tabela_margem_percentual = criar_tabela_margem_percentual(df_filtrado)
            
            if tabela_margem_percentual is not None:
                st.dataframe(
                    tabela_margem_percentual,
                    use_container_width=True,
                    height=400
                )
                
                st.markdown(""" 
                **Como interpretar a tabela:**
                - As linhas mostram o m√™s de primeira compra (safra) dos clientes
                - As colunas mostram os meses subsequentes de compra
                - Os valores representam a margem percentual
                - A coluna 'Total Geral' mostra a m√©dia da margem percentual por safra
                """)

        with tab5:  # Nova aba para a tabela de notas
            st.write("### Tabela de Notas Emitidas")
            tabela_notas = criar_tabela_notas(df_filtrado)
            
            if tabela_notas is not None:
                st.dataframe(
                    tabela_notas,
                    use_container_width=True,
                    height=400
                )
                
                st.markdown(""" 
                **Como interpretar a tabela:**
                - As linhas mostram o m√™s de primeira compra (safra) dos clientes
                - As colunas mostram os meses subsequentes de compra
                - Os valores representam a quantidade de notas emitidas
                - A coluna 'Total Geral' mostra o total de notas emitidas por safra
                """)

        with tab6:  # Nova aba para a tabela de quantidade de vendas
            st.write("### Tabela de Volume Vendido")
            tabela_quantidade = criar_tabela_quantidade(df_filtrado)
            
            if tabela_quantidade is not None:
                st.dataframe(
                    tabela_quantidade,
                    use_container_width=True,
                    height=400
                )
                
                st.markdown(""" 
                **Como interpretar a tabela:**
                - As linhas mostram o m√™s de primeira compra (safra) dos clientes
                - As colunas mostram os meses subsequentes de compra
                - Os valores representam a quantidade total de vendas
                - A coluna 'Total Geral' mostra a quantidade total por safra
                """)

elif pagina == "An√°lise Explorat√≥ria":
    # Exibir as primeiras linhas do DataFrame
    st.subheader("Visualiza√ß√£o dos Dados")
    st.dataframe(df_filtrado.head())

    # An√°lise Explorat√≥ria
    st.subheader("An√°lise Explorat√≥ria")

    # Exibir informa√ß√µes do DataFrame
    st.write("Informa√ß√µes do DataFrame:")
    st.write(df_filtrado.info())

    # Criar abas para organizar a an√°lise
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["Informa√ß√µes", "Estat√≠sticas Descritivas", "Distribui√ß√£o", "Correla√ß√£o", "Pr√©-processamento"])

    with tab1:
        # st.write("## Bem-vindo √† P√°gina de An√°lise Explorat√≥ria!")
        # import analise_preditiva  # Importa a nova p√°gina
        # Faturamento total
        faturamento_total = df_filtrado['faturamento'].sum()
        st.write(f"**Faturamento Total:** R$ {faturamento_total:,.2f}")

        # Faturamento m√©dio mensal
        faturamento_mensal = df_filtrado.groupby(df_filtrado['datamovimento'].dt.to_period('M'))['faturamento'].sum()
        faturamento_medio_mensal = faturamento_mensal.mean()
        st.write(f"**Faturamento M√©dio Mensal:** R$ {faturamento_medio_mensal:,.2f}")

        # Faturamento m√©dio por cliente
        faturamento_medio_por_cliente = faturamento_total / df_filtrado['codigocliente'].nunique()
        st.write(f"**Faturamento M√©dio por Cliente:** R$ {faturamento_medio_por_cliente:,.2f}")

        # Faturamento m√©dio por nota fiscal
        faturamento_medio_por_nota = faturamento_total / df_filtrado['notasaida'].nunique()
        st.write(f"**Faturamento M√©dio por Nota Fiscal:** R$ {faturamento_medio_por_nota:,.2f}")

        # Faturamento m√©dio por nome_cluster
        faturamento_por_nome_cluster = df_filtrado.groupby('nome_cluster')['faturamento'].sum()
        faturamento_medio_por_nome_cluster = faturamento_por_nome_cluster.mean()
        st.write(f"**Faturamento M√©dio por Cluster:** R$ {faturamento_medio_por_nome_cluster:,.2f}")

        # Margem por nome_cluster
        df_filtrado.loc[:, 'margem'] = df_filtrado['faturamento'] - df_filtrado['custo']  # Calcular a margem usando .loc
        margem_por_nome_cluster = df_filtrado.groupby('nome_cluster')['margem'].mean()
        st.write("**Margem por Cluster:**")
        st.dataframe(margem_por_nome_cluster)

    with tab2:
        # Exibir estat√≠sticas descritivas
        st.subheader("Estat√≠sticas Descritivas")
        tabela_estatisticas = df_filtrado.describe()
        st.dataframe(tabela_estatisticas.style.background_gradient(cmap='viridis'))

        # EDA
        # Tipos de dados
        # st.write("## An√°lise Explorat√≥ria de Dados")
        st.subheader("Tipos de Dados das Colunas")
        st.write(df_filtrado.dtypes)

        # Existem valores ausentes ou nulos? Quais colunas s√£o mais afetadas?
        st.subheader("Existem valores ausentes ou nulos?")
        valores_ausentes = df_filtrado.isna().sum()
        st.dataframe(valores_ausentes)

        # Identificar as colunas mais afetadas por valores ausentes ou nulos
        colunas_afetadas = valores_ausentes[valores_ausentes > 0].sort_values(ascending=False)
        st.subheader("Colunas Mais Afetadas por Valores Ausentes ou Nulos")
        st.dataframe(colunas_afetadas)

    with tab3:
        # Compreens√£o das vari√°veis
        # Qual √© a vari√°vel alvo?
        st.subheader("Defini√ß√£o da Vari√°vel Alvo")
        variavel_alvo = st.selectbox("Selecione a Vari√°vel Alvo:", ["faturamento", "margem", "quantidade"])
        st.write(f"Vari√°vel Alvo Selecionada: {variavel_alvo}")

        # Quais vari√°veis s√£o categ√≥ricas e quais s√£o num√©ricas?

        # definir manualmente as vari√°veis que s√£o num√©ricas mas que s√£o, na verdade, categ√≥ricas.
        df_filtrado['codigocliente'] = df_filtrado['codigocliente'].astype(str)
        df_filtrado['codigofilial'] = df_filtrado['codigofilial'].astype(str)
        df_filtrado['notasaida'] = df_filtrado['notasaida'].astype(str)

        # Identificar as vari√°veis categ√≥ricas e num√©ricas, excluindo a vari√°vel alvo
        variaveis_categoricas = df_filtrado.select_dtypes(include=['object']).columns.difference(['variavel_alvo'])
        variaveis_numericas = df_filtrado.select_dtypes(include=['int64', 'float64']).columns.difference(['variavel_alvo'])

        st.subheader("Vari√°veis Categ√≥ricas")
        st.write("As seguintes vari√°veis s√£o categ√≥ricas:")
        st.write(variaveis_categoricas)

        st.subheader("Vari√°veis Num√©ricas")
        st.write("As seguintes vari√°veis s√£o num√©ricas:")
        st.write(variaveis_numericas)

        # Distribui√ß√£o e Estatisticas b√°sicas
        st.subheader("Distribui√ß√£o da Vari√°vel Alvo")

        # Garantir que a vari√°vel alvo seja num√©rica
        df_filtrado[variavel_alvo] = pd.to_numeric(df_filtrado[variavel_alvo], errors='coerce')

        # Adicionar op√ß√£o para gerar o gr√°fico de distribui√ß√£o
        mostrar_distribuicao = st.checkbox("Mostrar Distribui√ß√£o da Vari√°vel Alvo", value=False)

        if mostrar_distribuicao:
            plt.figure(figsize=(10, 6))
            sns.histplot(df_filtrado[variavel_alvo].dropna(), kde=True, color='blue')  # Remover NaN para o histograma
            plt.title(f"Distribui√ß√£o da Vari√°vel Alvo: {variavel_alvo}")
            plt.xlabel(variavel_alvo)
            plt.ylabel("Frequ√™ncia")
            st.pyplot(plt)

        # Existem valores extremos ou outliwes em vari√°veis num√©ricas?
        st.subheader("Existem valores extremos ou outliers em vari√°veis num√©ricas?")

        # Identificar valores extremos ou outliers em vari√°veis num√©ricas
        valores_extremos = df_filtrado[variaveis_numericas].apply(lambda x: x[(np.abs(x-x.mean())>=(3*x.std()))], axis=1)

        # Mostrar as vari√°veis com valores extremos ou outliers
        st.dataframe(valores_extremos)

        # Identificar quais vari√°veis t√™m mais valores extremos ou outliers
        contagem_valores_extremos = valores_extremos.sum().sort_values(ascending=False)
        st.subheader("Vari√°veis com Mais Valores Extremos ou Outliers")
        st.dataframe(contagem_valores_extremos)

        # Como as vari√°veis categ√≥ricas est√£o distribu√≠das?
        st.subheader("Distribui√ß√£o das Vari√°veis Categ√≥ricas")

        mostrar_dist_categorias = st.checkbox("Mostrar Distribui√ß√£o de Vari√°veis Categ√≥ricas", value=False)

        if mostrar_dist_categorias:
            # Criar um gr√°fico de barras para cada vari√°vel categ√≥rica
            # Vamos filtrar apenas algumas vari√°veis para verificar a distribui√ß√£o delas
            variaveis_selecionadas = ['nome_cluster', 'ufcliente', 'gerentecarteira']
            for variavel in variaveis_selecionadas:
                plt.figure(figsize=(10, 6))
                sns.countplot(x=variavel, data=df_filtrado)
                plt.title(f"Distribui√ß√£o de {variavel}")
                plt.xlabel(variavel)
                plt.ylabel("Frequ√™ncia")
                st.pyplot(plt)
        
    with tab4:    
        # Relacionamento e Padr√µes
        # Corre√ß√£o

        # Existe correla√ß√£o entre as vari√°veis num√©ricas e a vari√°vel-alvo?
        st.subheader("Existe correla√ß√£o entre as vari√°veis num√©ricas e a vari√°vel-alvo?")

        # st.write("Colunas dispon√≠veis no DataFrame:", df_filtrado.columns.tolist())

        # Verificar se as vari√°veis num√©ricas e a vari√°vel alvo est√£o presentes no DataFrame
        variaveis_a_verificar = variaveis_numericas #+ [variavel_alvo]
        variaveis_presentes = [var for var in variaveis_a_verificar if var in df_filtrado.columns]

        if len(variaveis_presentes) == len(variaveis_a_verificar):
            # Calcular a matriz de correla√ß√£o
            matriz_correlacao = df_filtrado[variaveis_presentes].corr()
            # Mostrar a matriz de correla√ß√£o
            st.dataframe(matriz_correlacao)
        else:
            st.warning("Algumas vari√°veis n√£o est√£o presentes no DataFrame. Verifique os nomes das colunas.")
        
        st.markdown("""
        **Correla√ß√£o:**
        
        - Valor 1: Indica uma correla√ß√£o positiva perfeita. Isso significa que, √† medida que uma vari√°vel aumenta, a outra tamb√©m aumenta de forma proporcional.
        - Valor -1: Indica uma correla√ß√£o negativa perfeita. Isso significa que, √† medida que uma vari√°vel aumenta, a outra diminui de forma proporcional.
        - Valor 0: Indica que n√£o h√° correla√ß√£o linear entre as vari√°veis. Isso significa que as mudan√ßas em uma vari√°vel n√£o est√£o relacionadas √†s mudan√ßas na outra.
        """)


    with tab5:
        st.title("Fase de Pr√©-processamento")
        st.subheader("Prepara√ß√£o dos Dados para An√°lise")

        # Rafa comentou sobre n√£o comparar m√™s a m√™s anos anteriores a 2023 com 2025 e considerar somente o crescimento anual
        # Ao contr√°rio de 2024

        # Tratamento de dados ausentes na coluna 'rede'
        df_filtrado['rede'].fillna('sem rede', inplace=True)

        # Tratamento de dados ausentes nas colunas 'custo' e 'margem'
        df_filtrado['custo'].fillna(method='bfill', inplace=True)
        df_filtrado['margem'].fillna(method='bfill', inplace=True)

        df_processado = df_filtrado.copy()
        
        # Excluir registros com 'rede' igual a VILLA ou TOQUE DE PEIXE
        st.warning("Excluindo rede Villa e Toque de Peixe")
        # Verificar se df_filtrado foi definido antes de processamento
        if df_filtrado is not None:
            st.success("DataFrame filtrado carregado com sucesso.")
            df_processado = df_filtrado.copy()
            df_processado = df_processado[df_processado['rede'].isin(['VILLA', 'TOQUE DE PEIXE']) == False]
        else:
            st.error("DataFrame filtrado n√£o foi definido. Verifique as etapas anteriores de processamento.")

        # Calcular o pre√ßo m√©dio unit√°rio vendido
        if df_processado is not None:
            df_processado['preco_medio_unitario'] = df_processado['faturamento'] / df_processado['quantidade']
            

        st.subheader("Tratamento de Outliers")


        # Vamos criar uma coluna cod_gerente_carteira apenas com o numeral encontrado √† direta da dos valores da vari√°vel 
        df_processado['cod_gerente_carteira'] = df_processado['gerentecarteira'].apply(lambda x: re.search(r'\d+', x).group() if re.search(r'\d+', x) else None)
        # Fazer o mesmo para nome_cluster
        df_processado['cod_nome_cluster'] = df_processado['nome_cluster'].apply(lambda x: re.search(r'\d+', x).group() if re.search(r'\d+', x) else None)
        # Fazer o mesmo para supervisor_carteira
        df_processado['cod_supervisor_carteira'] = df_processado['supervisorcarteira'].apply(lambda x: re.search(r'\d+', x).group() if re.search(r'\d+', x) else None)


        # Tratar as vari√°veis cod_gerente_carteira, cod_nome_cluster e cod_supervisor_carteira como categ√≥ricas
        df_processado['cod_gerente_carteira'] = df_processado['cod_gerente_carteira'].astype(str)
        df_processado['cod_nome_cluster'] = df_processado['cod_nome_cluster'].astype(str)
        df_processado['cod_supervisor_carteira'] = df_processado['cod_supervisor_carteira'].astype(str)


        colunas_a_remover = ['cliente', 'nome_cluster', 'rede', 'gerentevenda', 'supervisorvenda', 'consultorvenda', 'gerentecarteira', 'supervisorcarteira', 'consultorcarteira', 'ufcliente', 'codigocliente', 'codigofilial', 'notasaida']
        for coluna in colunas_a_remover:
            if coluna in df_processado.columns:
                df_processado.drop(columns=[coluna], inplace=True)


        # Identificar as vari√°veis categ√≥ricas e num√©ricas, excluindo a vari√°vel alvo
        variaveis_categoricas_p = df_processado.select_dtypes(include=['object']).columns.difference([variavel_alvo])
        variaveis_numericas_p = df_processado.select_dtypes(include=['int64', 'float64']).columns.difference([variavel_alvo])


        # Aplicar escalas logar√≠tmicas √†s vari√°veis num√©ricas
        for var in variaveis_numericas_p:
            df_processado[var] = df_processado[var].apply(lambda x: np.log(x) if x > 0 else x)

        st.success("Escalas logar√≠tmicas aplicadas √†s vari√°veis num√©ricas com sucesso.")

        # Mostrar o DataFrame ap√≥s o tratamento de outliers
        st.dataframe(df_processado.head())

        # Adicionar vari√°veis temporais
        if df_processado is not None:
            # Converter DATAMOVIMENTO para datetime se ainda n√£o estiver
            df_processado['datamovimento'] = pd.to_datetime(df_processado['datamovimento'])
            
            # Criar novas vari√°veis temporais
            df_processado['dia_da_semana'] = df_processado['datamovimento'].dt.weekday  # Dia da semana
            df_processado['mes'] = df_processado['datamovimento'].dt.month  # M√™s
            df_processado['sazonalidade'] = df_processado['datamovimento'].dt.month % 12 // 3 + 1  # Sazonalidade (1: Primavera, 2: Ver√£o, 3: Outono, 4: Inverno)


            # Mostrar o DataFrame ap√≥s a cria√ß√£o de vari√°veis temporais
            st.success("Cria√ß√£o de vari√°veis temporais com sucesso.")
            st.dataframe(df_processado.head())


    
        st.subheader("Fase de Modelagem e Treinamento do Modelo")
        st.write("Divis√£o dos dados")

        from sklearn.model_selection import train_test_split

        # Divis√£o dos dados em treino, valida√ß√£o e teste
        X = df_processado.drop(columns=[variavel_alvo])
        y = df_processado[variavel_alvo]
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.143, random_state=42)

        st.success("Divis√£o dos dados em treino, valida√ß√£o e teste com sucesso.")
        # st.write("√çndices de treino:", X_train.index)
        # st.write("√çndices de valida√ß√£o:", X_val.index)
        # st.write("√çndices de teste:", X_test.index)
        # Salvar df_processado na sess√£o
        st.session_state.df_processado = df_processado  # Salvar df_processado na sess√£o



if pagina == "Modelagem e Treinamento":
    if 'df_processado' in st.session_state:
        # Iniciar a fase de modelagem
        st.title("Fase de Modelagem e Treinamento do Modelo")
        st.subheader("Divis√£o dos dados")


        # Recuperar df_processado da sess√£o
        df_processado = st.session_state.df_processado
        # Remover registros do m√™s corrente de df_processado
        mes_atual = pd.Timestamp.now().to_period('M')
        df_processado = df_processado[df_processado['datamovimento'].dt.to_period('M') != mes_atual]
        
        st.success(f"Registros do m√™s atual ({mes_atual}) removidos do DataFrame.")

        st.subheader("Defini√ß√£o da Vari√°vel Alvo")
        variavel_alvo = st.selectbox("Selecione a Vari√°vel Alvo:", ["faturamento", "margem", "quantidade"])
        st.write(f"Vari√°vel Alvo Selecionada: {variavel_alvo}")

        from sklearn.model_selection import train_test_split

        # Divis√£o dos dados em treino, valida√ß√£o e teste
        X = df_processado.drop(columns=[variavel_alvo])
        y = df_processado[variavel_alvo]
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.143, random_state=42)

        st.success("Divis√£o dos dados em treino, valida√ß√£o e teste com sucesso.")

        # Inclus√£o da sele√ß√£o do modelo
        st.subheader("Escolha do Modelo")

        modelos_disponiveis = [
            'Nenhum',
            'Prophet',
            'Regress√£o Linear', 
            '√Årvore de Decis√£o', 
            'Random Forest', 
            'Gradient Boosting', 
            'XGBoost'
        ]
        # Adicionar selectbox na sidebar para escolha do modelo
        modelo_selecionado = st.selectbox(
            "Escolha o Modelo de Machine Learning", 
            modelos_disponiveis
        )


    # Exibir o modelo selecionado
    st.write(f"Modelo selecionado: {modelo_selecionado}")

    if modelo_selecionado == 'Nenhum':
        st.subheader("Nenhum modelo selecionado")



    if modelo_selecionado == 'Prophet':
        # Preparando dados para o Prophet
        df_prophet = df_processado[['datamovimento', variavel_alvo]].copy()
        df_prophet.columns = ['ds', 'y']  # Renomeando colunas conforme requerido pelo Prophet
        df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])

        # Agregar dados di√°rios para mensais
        df_prophet = df_prophet.resample('M', on='ds').sum().reset_index()

        # Adicionando feriados brasileiros usando make_holidays
        from prophet import Prophet
        from prophet.make_holidays import make_holidays_df
        from prophet.diagnostics import cross_validation, performance_metrics

        # Criar dataframe de feriados brasileiros
        feriados_brasileiros = make_holidays_df(year_list=[2018, 2019, 2020, 2021, 2022, 2023, 2024], country='BR')  # Adicione os anos desejados
        feriados_brasileiros['holiday'] = 'feriado'

        # Inicializando e treinando o modelo Prophet
        modelo_prophet = Prophet(
            daily_seasonality=False,
            weekly_seasonality=True,
            yearly_seasonality=True,
            holidays=feriados_brasileiros,
            changepoint_prior_scale=0.2,  # Ajuste conforme necess√°rio
            seasonality_prior_scale=10.0   # Ajuste conforme necess√°rio
        )

        # Adicionando sazonalidade mensal
        # modelo_prophet.add_seasonality(name='mensal', period=30.5, fourier_order=5)

        # Ajustando o modelo
        modelo_prophet.fit(df_prophet)

        # Criando per√≠odo futuro para previs√£o
        futuro = modelo_prophet.make_future_dataframe(periods=12, freq='ME')  # Previs√£o para os pr√≥ximos 12 meses
        previsao = modelo_prophet.predict(futuro)

        # Visualizando resultados com Plotly
        import plotly.graph_objects as go

        fig = go.Figure()

        # Gr√°fico de linha para a previs√£o
        fig.add_trace(go.Scatter(x=previsao['ds'], y=previsao['yhat'], mode='lines', name='Previs√£o', line=dict(color='blue')))
        fig.add_trace(go.Scatter(x=previsao['ds'], y=previsao['yhat_lower'], mode='lines', name='Limite Inferior', line=dict(color='lightblue', dash='dash')))
        fig.add_trace(go.Scatter(x=previsao['ds'], y=previsao['yhat_upper'], mode='lines', name='Limite Superior', line=dict(color='lightblue', dash='dash')))
        
        # Adicionando dados reais
        fig.add_trace(go.Scatter(x=df_prophet['ds'], y=df_prophet['y'], mode='markers', name='Dados Reais', marker=dict(color='red')))

        # Atualizando layout
        fig.update_layout(title='Previs√£o com Prophet', xaxis_title='Data', yaxis_title=variavel_alvo)
        
        # Exibir gr√°fico interativo
        st.plotly_chart(fig)

        
        # Adicionar checkbox para valida√ß√£o cruzada
        aplicar_validacao_cruzada = st.checkbox("Aplicar Valida√ß√£o Cruzada", value=False)

        if aplicar_validacao_cruzada:
            # Aplicar valida√ß√£o cruzada
            df_cv = cross_validation(modelo_prophet, initial='365 days', period='30 days', horizon='90 days')

            # Calcular m√©tricas de desempenho
            df_p = performance_metrics(df_cv)

            # Exibir as m√©tricas de desempenho
            st.write("### M√©tricas de Desempenho da Valida√ß√£o Cruzada")
            st.dataframe(df_p)

            # Visualizar os resultados da valida√ß√£o cruzada
            fig_cv = modelo_prophet.plot(df_cv)
            st.pyplot(fig_cv)

        # Adicionar explica√ß√£o sobre o Prophet e os resultados
        st.markdown(""" 
        ### Sobre o Prophet
        O Prophet √© uma ferramenta de previs√£o desenvolvida pelo Facebook, projetada para lidar com s√©ries temporais que apresentam padr√µes sazonais e tend√™ncias. Ele √© especialmente √∫til para dados que t√™m per√≠odos de sazonalidade di√°ria, semanal ou anual, e pode lidar com dados ausentes e mudan√ßas nas tend√™ncias.

        ### Resultados da Previs√£o
        A tabela abaixo apresenta as previs√µes mensais para o vari√°vel alvo ao longo dos anos. Cada c√©lula representa a previs√£o do valor para um determinado m√™s e ano. A linha 'Total' fornece a soma das previs√µes para cada ano, permitindo uma vis√£o geral do desempenho esperado ao longo do tempo.
        """)

        # Imprimir as colunas do DataFrame de previs√£o
        # st.subheader("Colunas do DataFrame de Previs√£o")
        # st.write(previsao.columns)

        # Criar tabela pivot com m√™s em linhas e ano em colunas
        previsao['ano'] = previsao['ds'].dt.year
        previsao['mes'] = previsao['ds'].dt.month
        tabela_pivot = previsao.pivot_table(index='mes', columns='ano', values='yhat', aggfunc='sum')

        # Adicionar linha de totais
        tabela_pivot.loc['Total'] = tabela_pivot.sum()

        # Exibir tabela pivot com formata√ß√£o de duas casas decimais
        st.subheader("Tabela Pivot da Previs√£o")
        st.dataframe(tabela_pivot.style.format("{:.2f}"))

        # Componentes da previs√£o
        fig_componentes = modelo_prophet.plot_components(previsao)

        # Extrair os dados dos componentes
        trend = previsao[['ds', 'trend']]
        seasonal = previsao[['ds', 'weekly']]
        holidays = previsao[['ds', 'holidays']]
        yearly = previsao[['ds', 'yearly']]

        # Criar gr√°ficos interativos com Plotly
        fig_trend = go.Figure()
        fig_trend.add_trace(go.Scatter(x=trend['ds'], y=trend['trend'], mode='lines', name='Tend√™ncia', line=dict(color='blue')))
        fig_trend.update_layout(title='Tend√™ncia', xaxis_title='Data', yaxis_title='Valor')

        fig_seasonal = go.Figure()
        fig_seasonal.add_trace(go.Scatter(x=seasonal['ds'], y=seasonal['weekly'], mode='lines', name='Sazonalidade', line=dict(color='orange')))
        fig_seasonal.update_layout(title='Sazonalidade', xaxis_title='Data', yaxis_title='Valor')

        fig_yealy = go.Figure()
        fig_yealy.add_trace(go.Scatter(x=yearly['ds'], y=yearly['yearly'], mode='lines', name='Sazonalidade Anual', line=dict(color='green')))
        fig_yealy.update_layout(title='Sazonalidade Anual', xaxis_title='Data', yaxis_title='Valor')


        # Exibir gr√°ficos interativos
        st.plotly_chart(fig_trend)
        st.plotly_chart(fig_seasonal)
        st.plotly_chart(fig_yealy)
        if 'holidays' in previsao.columns:
            fig_holidays = go.Figure()
            fig_holidays.add_trace(go.Scatter(x=holidays['ds'], y=holidays['holidays'], mode='lines', name='Feriados', line=dict(color='green')))
            fig_holidays.update_layout(title='Efeito dos Feriados', xaxis_title='Data', yaxis_title='Valor')
            
            # Exibir gr√°fico de feriados
            st.plotly_chart(fig_holidays)

        # Avalia√ß√£o da acur√°cia
        from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error

        # Calcular MSE para o horizonte desejado
        mse = mean_squared_error(df_prophet['y'], previsao['yhat'][:len(df_prophet)])
        # Calcular MAE (Mean Absolute Error)
        mae = mean_absolute_error(df_prophet['y'], previsao['yhat'][:len(df_prophet)])
        
        # Calcular MAPE (Mean Absolute Percentage Error)
        mape = mean_absolute_percentage_error(df_prophet['y'], previsao['yhat'][:len(df_prophet)])

        st.write(f"**Erro Quadr√°tico M√©dio (MSE):** {mse:.2f}")
        st.write(f"**Erro Absoluto M√©dio (MSE):** {mae:.2f}")
        st.write(f"**Erro Absoluto M√©dio Percentual (MSE):** {mape:.2f}")

        # Explica√ß√£o do Erro Quadr√°tico M√©dio (MSE)
        st.markdown("### Interpreta√ß√£o do Erro Quadr√°tico M√©dio (MSE)")
        
        if mse is not None:
            if mse < 0.1:
                st.success(f"O MSE de {mse:.2f} indica um modelo com excelente precis√£o. Quanto mais pr√≥ximo de zero, melhor o desempenho do modelo.")
                st.markdown("""
                - **Interpreta√ß√£o:** Os valores previstos est√£o muito pr√≥ximos dos valores reais
                - Baixa dispers√£o entre predi√ß√µes e valores observados
                - Alta confiabilidade nas previs√µes
                """)
            elif mse < 1:
                st.info(f"O MSE de {mse:.2f} sugere um modelo com boa precis√£o. H√° uma varia√ß√£o moderada entre predi√ß√µes e valores reais.")
                st.markdown("""
                - **Interpreta√ß√£o:** Os valores previstos t√™m uma precis√£o razo√°vel
                - Alguma dispers√£o entre predi√ß√µes e valores observados
                - Modelo funciona bem, mas pode ser aprimorado
                """)
            else:
                st.warning(f"O MSE de {mse:.2f} indica que o modelo tem espa√ßo para melhorias significativas.")
                st.markdown("""
                - **Interpreta√ß√£o:** Existe uma diferen√ßa consider√°vel entre valores previstos e reais
                - Alta dispers√£o nos resultados
                - Recomenda-se revisar features, t√©cnicas de modelagem ou coletar mais dados
                """)

        # An√°lise de Res√≠duos para Regress√£o Linear
        st.subheader("An√°lise de Res√≠duos")
        
        # Calcular res√≠duos
        residuos = y_test - previsao
        
        # Gr√°fico de dispers√£o dos res√≠duos
        plt.figure(figsize=(10, 6))
        plt.scatter(previsao, residuos, color='green', alpha=0.7)
        plt.title("Gr√°fico de Dispers√£o dos Res√≠duos")
        plt.xlabel("Valores Previstos")
        plt.ylabel("Res√≠duos")
        plt.axhline(y=0, color='red', linestyle='--')
        st.pyplot(plt)
        
        # Histograma dos res√≠duos
        plt.figure(figsize=(10, 6))
        plt.hist(residuos, bins=30, color='purple', alpha=0.7)
        plt.title("Distribui√ß√£o dos Res√≠duos")
        plt.xlabel("Res√≠duos")
        plt.ylabel("Frequ√™ncia")
        st.pyplot(plt)
        
        # Explica√ß√£o da an√°lise de res√≠duos
        st.markdown("""
        ### Interpreta√ß√£o da An√°lise de Res√≠duos
        
        A an√°lise de res√≠duos ajuda a avaliar a qualidade do modelo de regress√£o linear:
        
        1. **Gr√°fico de Dispers√£o dos Res√≠duos**:
        - Idealmente, os res√≠duos devem estar distribu√≠dos aleatoriamente em torno da linha zero
        - Padr√µes ou tend√™ncias no gr√°fico indicam que o modelo pode estar deixando de capturar alguma rela√ß√£o importante
        
        2. **Histograma dos Res√≠duos**:
        - Os res√≠duos devem seguir aproximadamente uma distribui√ß√£o normal
        - Distribui√ß√£o sim√©trica em torno de zero sugere um bom ajuste do modelo
        
        #### O que procurar:
        - Res√≠duos concentrados pr√≥ximos a zero
        - Distribui√ß√£o aproximadamente sim√©trica 
        - Aus√™ncia de padr√µes sistem√°ticos
        
        #### Poss√≠veis problemas:
        - Res√≠duos com padr√£o n√£o aleat√≥rio: indica vi√©s no modelo
        - Distribui√ß√£o muito assim√©trica: sugere que o modelo n√£o captura bem a varia√ß√£o dos dados
        """)

    # Regress√£o Linear
    if modelo_selecionado == 'Regress√£o Linear':
        # Preparando dados para Regress√£o Linear
        from sklearn.model_selection import train_test_split
        from sklearn.linear_model import LinearRegression
        from sklearn.metrics import mean_squared_error, r2_score
        import numpy as np
        import matplotlib.pyplot as plt
        import seaborn as sns  # Importar seaborn para melhor visualiza√ß√£o

        # Selecionar features para o modelo
        features = st.multiselect(
            "Selecione as Features para o Modelo de Regress√£o Linear", 
            list(df_processado.select_dtypes(include=['int64', 'float64']).columns)
        )

        # Preparar dados de treino e teste
        X = df_processado[features]
        y = df_processado[variavel_alvo]

        # Dividir dados em treino e teste
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Treinar modelo de Regress√£o Linear
        modelo_linear = LinearRegression()
        modelo_linear.fit(X_train, y_train)

        # Fazer previs√µes
        previsoes = modelo_linear.predict(X_test)

        # Avaliar modelo
        mse = mean_squared_error(y_test, previsoes)
        r2 = r2_score(y_test, previsoes)

        # Visualizar resultados
        st.subheader("Resultados da Regress√£o Linear")
        
        # Gr√°fico de valores reais vs previstos
        plt.figure(figsize=(12, 8))
        sns.scatterplot(x=y_test, y=previsoes, color='blue', alpha=0.7)  # Usar seaborn para o gr√°fico de dispers√£o
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # Linha de refer√™ncia
        plt.title("Valores Reais vs Previstos", fontsize=16)  # T√≠tulo com tamanho de fonte
        plt.xlabel("Valores Reais", fontsize=12)  # R√≥tulo do eixo x com tamanho de fonte
        plt.ylabel("Valores Previstos", fontsize=12)  # R√≥tulo do eixo y com tamanho de fonte
        plt.grid(True)  # Adicionar grade para melhor visualiza√ß√£o
        st.pyplot(plt)

        # M√©tricas de desempenho
        st.write(f"**Erro Quadr√°tico M√©dio (MSE):** {mse:.2f}")
        st.write(f"**Coeficiente de Determina√ß√£o (R¬≤):** {r2:.2f}")

        # Coeficientes do modelo
        coeficientes = pd.DataFrame({
            'Feature': features,
            'Coeficiente': modelo_linear.coef_
        })
        st.subheader("Coeficientes do Modelo")
        st.dataframe(coeficientes)

        # Previs√£o para 2025
        st.subheader("Previs√£o para 2025")
        
        # Criar DataFrame para os meses de 2025
        meses_2025 = pd.date_range(start='2025-01-01', end='2025-12-31', freq='M')
        df_previsao_2025 = pd.DataFrame(meses_2025, columns=['datamovimento'])
        
        # Adicionar colunas de caracter√≠sticas necess√°rias (exemplo)
        # Aqui voc√™ deve adicionar as colunas que seu modelo espera
        # Exemplo: df_previsao_2025['feature1'] = valor
        # df_previsao_2025['feature2'] = valor
        # Certifique-se de que as colunas correspondam √†s que foram usadas no treinamento do modelo

        # Exemplo de preenchimento de caracter√≠sticas (substitua com seus dados reais)
        df_previsao_2025[features] = 0  # Preencher com zeros para todas as features din√¢micas
        # Adicione mais caracter√≠sticas conforme necess√°rio

        # Fazer previs√µes para 2025
        previsoes_2025 = modelo_linear.predict(df_previsao_2025[features])

        # Adicionar previs√µes ao DataFrame
        df_previsao_2025['Previsao'] = previsoes_2025

        # Exibir tabela de previs√µes
        st.dataframe(df_previsao_2025[['datamovimento', 'Previsao']].style.format({"Previsao": "${:,.2f}"}))



    # Arvore de decis√£o
    if modelo_selecionado == '√Årvore de Decis√£o':
        # Preparar dados para √Årvore de Decis√£o
        
        features = st.multiselect(
            "Selecione as Features para o Modelo de √Årvore de Decis√£o", 
            list(df_processado.select_dtypes(include=['int64', 'float64']).columns.difference([variavel_alvo]))
        )

        # Verificar se features foram selecionadas
        if not features:
            st.warning("Por favor, selecione pelo menos uma feature.")
        else:
            # Preparar dados de treino e teste
            X = df_processado[features]
            y = df_processado[variavel_alvo]

            # Dividir dados em treino e teste
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

            # Treinar modelo de √Årvore de Decis√£o
            arvore_decisao = DecisionTreeRegressor(random_state=42)
            arvore_decisao.fit(X_train, y_train)

            # Fazer previs√µes
            previsoes = arvore_decisao.predict(X_test)

            # Imprimir previs√µes em uma tabela
            previsoes_df = pd.DataFrame({
                'Valores Reais': y_test,
                'Valores Previstos': previsoes
            })
            st.subheader("Tabela de Previs√µes")
            st.dataframe(previsoes_df)

            # Avaliar modelo
            mse = mean_squared_error(y_test, previsoes)
            r2 = r2_score(y_test, previsoes)

            # Visualizar resultados
            st.subheader("Resultados da √Årvore de Decis√£o")
            
            # Gr√°fico de valores reais vs previstos
            plt.figure(figsize=(10, 6))
            plt.scatter(y_test, previsoes, color='green', alpha=0.7)
            plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
            plt.title("Valores Reais vs Previstos (√Årvore de Decis√£o)")
            plt.xlabel("Valores Reais")
            plt.ylabel("Valores Previstos")
            st.pyplot(plt)


            # M√©tricas de desempenho
            st.write(f"**Erro Quadr√°tico M√©dio (MSE):** {mse:.2f}")
            st.write(f"**Coeficiente de Determina√ß√£o (R¬≤):** {r2:.2f}")

            # Import√¢ncia das features
            importancia_features = pd.DataFrame({
                'Feature': features,
                'Import√¢ncia': arvore_decisao.feature_importances_
            }).sort_values('Import√¢ncia', ascending=False)
            
            st.subheader("Import√¢ncia das Features")
            st.dataframe(importancia_features)

            
            # Visualiza√ß√£o da √°rvore de decis√£o (opcional)
            st.subheader("Visualiza√ß√£o da √Årvore de Decis√£o")
            plt.figure(figsize=(20,10))
            plot_tree(arvore_decisao, feature_names=features, filled=True, rounded=True)
            plt.title("Estrutura da √Årvore de Decis√£o")
            st.pyplot(plt)


    # Modelo XGBoost

    if modelo_selecionado == 'XGBoost':
        # Importar bibliotecas necess√°rias
        from xgboost import XGBRegressor
        from sklearn.metrics import mean_squared_error, r2_score
        import matplotlib.pyplot as plt
        import numpy as np

        # Preparar os dados para o XGBoost
        # Remover colunas n√£o num√©ricas
        X = df_processado.drop(columns=[variavel_alvo, 'datamovimento', 'cod_gerente_carteira', 'cod_nome_cluster', 'cod_supervisor_carteira'])
        y = df_processado[variavel_alvo]

        # **Transformar dados di√°rios em mensais**
        df_processado['datamovimento'] = df_processado['datamovimento'].dt.to_period('M').dt.to_timestamp()

        # **Adicionar lags de 3 e 6 meses**
        df_processado['lag_3'] = df_processado[variavel_alvo].shift(3)
        df_processado['lag_6'] = df_processado[variavel_alvo].shift(6)

        # **Adicionar m√©dia m√≥vel das vendas**
        df_processado['media_movel_3'] = df_processado[variavel_alvo].rolling(window=3).mean()
        df_processado['media_movel_6'] = df_processado[variavel_alvo].rolling(window=6).mean()

        # **Adicionar indicadores sazonais**
        df_processado['mes'] = df_processado['datamovimento'].dt.month
        df_processado['sazonalidade'] = df_processado['mes'] % 12 // 3 + 1  # Sazonalidade (1: Primavera, 2: Ver√£o, 3: Outono, 4: Inverno)

        # Se houver colunas categ√≥ricas, voc√™ pode usar one-hot encoding
        X = pd.get_dummies(X, drop_first=True)  # Converte colunas categ√≥ricas em vari√°veis dummy

        # Dividir os dados em treino, valida√ß√£o e teste
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.143, random_state=42)

        # Inicializar e treinar o modelo XGBoost
        xgboost = XGBRegressor(
            n_estimators=100, 
            learning_rate=0.1, 
            random_state=42
        )
        xgboost.fit(X_train, y_train)

        # Fazer previs√µes
        previsoes = xgboost.predict(X_test)

        # Imprimir previs√µes em uma tabela
        previsoes_df = pd.DataFrame({
            'Valores Reais': y_test,
            'Valores Previstos': previsoes
        })
        st.subheader("Tabela de Previs√µes (XGBoost)")
        st.dataframe(previsoes_df)

        # Avaliar modelo
        mse = mean_squared_error(y_test, previsoes)
        r2 = r2_score(y_test, previsoes)

        # Visualizar resultados
        st.subheader("Resultados do XGBoost")
        
        # Gr√°fico de valores reais vs previstos
        plt.figure(figsize=(10, 6))
        plt.scatter(y_test, previsoes, color='purple', alpha=0.7)
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
        plt.title("Valores Reais vs Previstos (XGBoost)")
        plt.xlabel("Valores Reais")
        plt.ylabel("Valores Previstos")
        st.pyplot(plt)

        # M√©tricas de desempenho
        st.write(f"**Erro Quadr√°tico M√©dio (MSE):** {mse:.2f}")
        st.write(f"**Coeficiente de Determina√ß√£o (R¬≤):** {r2:.2f}")

        # Import√¢ncia das features
        features = X.columns.tolist()
        importancia_features = pd.DataFrame({
            'Feature': features,
            'Import√¢ncia': xgboost.feature_importances_
        }).sort_values('Import√¢ncia', ascending=False)
        
        st.subheader("Import√¢ncia das Features (XGBoost)")
        st.dataframe(importancia_features)

